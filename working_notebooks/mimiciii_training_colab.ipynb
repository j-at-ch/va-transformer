{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"name":"mimiciii_training_colab.ipynb","provenance":[{"file_id":"1GNps3iNQE_DJhzdE1RkCnqUIDlk_LGx2","timestamp":1625136080623}],"collapsed_sections":["Cg-gzA7tqjap","qoyiGyrsfZ29","MVUY6qYzkdOu","YYCK4nwgWlSu","-qev_muUEQYJ"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"dx4EQD3UfXjN"},"source":["## COLAB SETUP"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTSRguDDUyL9","executionInfo":{"status":"ok","timestamp":1625675815878,"user_tz":-60,"elapsed":17155,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}},"outputId":"0ad3bffb-f197-4737-edb7-927a19c7e031"},"source":["# mount your drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AfbwEJZ3gIX8","executionInfo":{"status":"ok","timestamp":1625675817767,"user_tz":-60,"elapsed":271,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["space = 'colab'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"5FN2tXvggDta","executionInfo":{"status":"ok","timestamp":1625675821516,"user_tz":-60,"elapsed":200,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["if space == 'colab':\n","    data_root = '/content/drive/MyDrive/Data'\n","    save_root = ''\n","else:\n","    data_root = 'C:/Users/james/Data/MIMIC/mimic-iii-clinical-database-1.4'\n","    save_root = 'C:/Users/james/Data/MIMIC/mimic-iii-chart-transformers'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"cmfULdfNVGDk"},"source":["!pip install x_transformers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZiNstdm5rLcI"},"source":["## TENSORBOARD UTILS"]},{"cell_type":"code","metadata":{"id":"5RPe_7XfrPE3","executionInfo":{"status":"ok","timestamp":1625675526558,"user_tz":-60,"elapsed":678,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["%reload_ext tensorboard"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQIzy2pj3E9L","executionInfo":{"status":"ok","timestamp":1625680004658,"user_tz":-60,"elapsed":197,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["from torch.utils.tensorboard import SummaryWriter\n","#writer = SummaryWriter()"],"execution_count":72,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mPGIdbjZro17"},"source":["Do writing! e.g. see [PyTorch tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html).\n","\n","Then `tensorboard --logdir runs`."]},{"cell_type":"code","metadata":{"id":"A9x-ZD4wLE3G"},"source":["tensorboard --logdir drive/MyDrive/Data/logs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cg-gzA7tqjap"},"source":["## PRE-PROCESSING"]},{"cell_type":"code","metadata":{"id":"iyvdkWonrunP"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import pickle as pickle\n","import torch\n","from sklearn.model_selection import train_test_split\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6YBDVsAsryy0"},"source":["# paths\n","\n","chartevents_path = os.path.join(data_root, \"CHARTEVENTS.csv\")\n","admissions_path = os.path.join(data_root,\"ADMISSIONS.csv\")\n","d_items_path = os.path.join(data_root, \"d_items.csv\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_FdSrcoqa88"},"source":["# read in admissions\n","\n","admissions = pd.read_csv(admissions_path,\n","                         parse_dates=['ADMITTIME', 'DISCHTIME'])\n","\n","# extract only those charted and apply labelling logic\n","\n","charted = admissions[admissions.HAS_CHARTEVENTS_DATA == 1]\n","charted.drop('ROW_ID', axis=1, inplace=True)\n","charted['HADM_IN_SEQ'] = charted.groupby('SUBJECT_ID')['ADMITTIME'].rank().astype(int)\n","charted = charted.sort_values(by=['SUBJECT_ID', 'HADM_IN_SEQ'])\n","charted['ADMITTIME_NEXT'] = charted.groupby('SUBJECT_ID')['ADMITTIME'].shift(-1)\n","charted['DIS2ADM'] = charted['ADMITTIME_NEXT'] - charted['DISCHTIME']\n","charted['READM<7'] = (charted['DIS2ADM'] < pd.Timedelta(days=7)).astype(int)\n","charted['READM<30'] = (charted['DIS2ADM'] < pd.Timedelta(days=30)).astype(int)\n","charted.set_index('HADM_ID', inplace=True)\n","\n","# get hadm_ids for the first admission\n","\n","first_indices = charted[charted.HADM_IN_SEQ == 1].index.to_numpy()\n","\n","# split first-hadm_ids into train, val, test and check.\n","\n","train_indices, surplus = train_test_split(first_indices, train_size=0.8)\n","val_indices, test_indices = train_test_split(surplus, test_size=0.5)\n","del surplus\n","assert set(first_indices) == set(train_indices) | set(val_indices) | set(test_indices)\n","\n","# helpers\n","\n","\n","def ts_to_posix(time):\n","    return pd.Timestamp(time, unit='s').timestamp()\n","\n","\n","def get_admittime(hadm_id):\n","    time = charted.loc[hadm_id, 'ADMITTIME']\n","    return ts_to_posix(time)\n","\n","\n","def get_from_charted(hadm_id, label):\n","    return charted.loc[hadm_id, label]\n","\n","\n","# token mappings\n","\n","d_items = pd.read_csv(d_items_path)\n","\n","token_shift = 1\n","pad_token = 0\n","\n","itemid2token = dict(zip(d_items['ITEMID'], range(token_shift, token_shift + len(d_items))))\n","\n","# add special tokens to the dictionary\n","itemid2token['[PAD]'] = pad_token\n","#itemid2token['[BOS]'] = 1\n","#itemid2token['[EOS]'] = 2\n","#itemid2token['[SEP]'] = 3\n","\n","token2itemid = {v: k for k, v in itemid2token.items()}\n","token2label = dict(zip(range(len(d_items)), d_items['LABEL']))\n","\n","with open(os.path.join(save_root, 'mappings.pkl'), 'wb') as f:\n","    pickle.dump({'itemid2token': itemid2token,\n","                 'token2itemid': token2itemid},\n","                f)\n","\n","\n","def map2token(itemid):\n","    return itemid2token[np.int(itemid)]\n","\n","\n","def map2itemid(token):\n","    return str(token2itemid[token])\n","\n","\n","def map2itemidstr(tokens):\n","    return ' '.join(list(map(map2itemid, tokens)))\n","\n","\n","# loop through sets and generate output files\n","\n","for subset in ['val', 'train', 'test']:\n","    print(f'Processing {subset} set data...')\n","\n","    # grouper for charts\n","\n","    gpdf = (pd.read_csv(chartevents_path, skiprows=0, \n","                        nrows=10000000 if space != 'colab',\n","                        header=0,\n","                        usecols=['HADM_ID', 'CHARTTIME', 'ITEMID'],\n","                        dtype={'HADM_ID': np.int},\n","                        converters={'ITEMID': map2token},\n","                        parse_dates=['CHARTTIME'])\n","            .query(f'HADM_ID.isin(@{subset}_indices)')\n","            .groupby(by='HADM_ID')\n","            )\n","\n","    # initialise\n","\n","    tokens = dict()\n","    times = dict()\n","    times_rel = dict()\n","    labels = dict()\n","\n","    # populate with entries\n","\n","    for i in gpdf.groups:\n","        time_origin = get_admittime(i)\n","        temp = gpdf.get_group(i).sort_values(by=\"CHARTTIME\")\n","        tokens[i] = np.array(temp['ITEMID'], dtype=int)\n","        times[i] = np.fromiter(\n","            map(ts_to_posix, temp['CHARTTIME']),\n","            dtype=np.int64\n","        )\n","        times_rel[i] = times[i] - time_origin\n","        labels[i] = {\n","            'readm_7': get_from_charted(i, 'READM<7'),\n","            'readm_30': get_from_charted(i, 'READM<30')\n","        }\n","\n","    # write out charts to pickle\n","\n","    save_path = os.path.join(save_root, f'{subset}_charts.pkl')\n","\n","    with open(save_path, 'wb') as f:\n","        pickle.dump({f'{subset}_tokens': tokens,\n","                     f'{subset}_times': times,\n","                     f'{subset}_times_rel': times_rel}, f)\n","\n","    del tokens, times, times_rel, gpdf\n","\n","    # write out labels to pickle\n","\n","    save_path = os.path.join(save_root, f'{subset}_labels.pkl')\n","\n","    with open(save_path, 'wb') as f:\n","        pickle.dump({f'{subset}_labels': labels}, f)\n","\n","    del labels\n","\n","    print(f'{subset} set data processed!')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eAUowrZpu3ed"},"source":["## SELF-SUPERVISED MODE\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0YD8BurHdbDu"},"source":["### THE MODEL"]},{"cell_type":"code","metadata":{"id":"WUjIH_4q_gzL","executionInfo":{"status":"ok","timestamp":1625675840556,"user_tz":-60,"elapsed":741,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["import os\n","import copy\n","import tqdm\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","import pickle as pickle\n","import torch\n","\n","from torch.utils.data import DataLoader, Dataset\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from x_transformers import TransformerWrapper, Decoder\n","from x_transformers.autoregressive_wrapper import AutoregressiveWrapper"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"myB-nKwoVmWe"},"source":["#### Mappings, Paths and Utils"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"RemqYJeTu2s7","executionInfo":{"status":"ok","timestamp":1625676119777,"user_tz":-60,"elapsed":709,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["# paths\n","\n","train_path = os.path.join(data_root, \"train_charts.pkl\")\n","val_path = os.path.join(data_root, \"val_charts.pkl\")\n","mapping_path = os.path.join(data_root, \"mappings.pkl\")\n","\n","# misc\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# token mappings:  # TODO: refactor to module where possible.\n","\n","with open(mapping_path, 'rb') as f:\n","    mappings = pickle.load(f)\n","    itemid2token = mappings['itemid2token']\n","    token2itemid = mappings['token2itemid']\n","    del mappings\n","\n","num_tokens = len(itemid2token)\n","\n","# token mappings: decoders\n","\n","\n","def decode_token(token):\n","    return str(token2itemid[token])\n","\n","\n","def decode_tokens(tokens):\n","    return ' '.join(list(map(decode_token, tokens)))\n","\n","\n","# get data\n","\n","def fetch_data(path, var_key):\n","    with open(path, 'rb') as f:\n","        data = pickle.load(f)\n","    return data[var_key]\n","\n","\n","trX = fetch_data(train_path, 'train_tokens')\n","vaX = fetch_data(val_path, 'val_tokens')\n","\n","data_train = {k: torch.from_numpy(v) for k, v in trX.items()}\n","data_val = {k: torch.from_numpy(v) for k, v in vaX.items()}\n","\n","\n","# yield from loader\n","\n","def cycle(loader):\n","    while True:\n","        for data in loader:\n","            yield data\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FgHrfl-GVe0l"},"source":["#### Constants & Model"]},{"cell_type":"code","metadata":{"id":"6GVoPb-bVdw5"},"source":["# constants & hyperparameters \n","\n","NUM_EPOCHS = 10\n","NUM_BATCHES = 1000\n","BATCH_SIZE = 4\n","GRADIENT_ACCUMULATE_EVERY = 4  # 4\n","LEARNING_RATE = 1e-4\n","VALIDATE_EVERY = 100\n","CHECKPOINT_AFTER = 100\n","GENERATE_EVERY = 100\n","GENERATE_LENGTH = 100\n","SEQ_LEN = 200\n","\n","# instantiate GPT-like decoder model\n","\n","\n","LAYER_SPEC = {'dim':100, 'depth':3, 'heads':4}  # full: 512, 6, 8\n","\n","model = TransformerWrapper(\n","    num_tokens=num_tokens,  # Expects each val in data to be [0, num_tokens)\n","    max_seq_len=SEQ_LEN, \n","    attn_layers=Decoder(\n","        dim=LAYER_SPEC['dim'],\n","        depth=LAYER_SPEC['depth'],\n","        heads=LAYER_SPEC['heads'])\n",")\n","\n","pre_model = AutoregressiveWrapper(model)\n","pre_model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IIMyYHwrUxST"},"source":["#### Datasets & Dataloaders"]},{"cell_type":"code","metadata":{"id":"fwNfiD4tUwFe","executionInfo":{"status":"ok","timestamp":1625675938589,"user_tz":-60,"elapsed":189,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["class ClsSamplerDataset(Dataset):  # TODO: tidy __getitem__ method with more natural pad operations.\n","    def __init__(self, data, seq_len, labels=None):\n","        super().__init__()\n","        self.data = data\n","        self.labels = labels\n","        self.seq_len = seq_len\n","        self.lookup = dict(zip(np.arange(len(self.data)), self.data.keys()))\n","\n","    def __getitem__(self, key):  # a.t.m. when data[key] shorter length than SEQ_LEN, padded with 0.\n","        index = self.lookup[key]\n","        item_len = self.data[index].size(0)\n","        rand_start = torch.randint(0, item_len - self.seq_len, (1,)) if item_len > self.seq_len else 0\n","        lenfromseq = min(item_len, self.seq_len)\n","        sample = torch.zeros(self.seq_len)\n","        sample[:lenfromseq] = self.data[index][rand_start: rand_start + lenfromseq]\n","\n","        if self.labels is not None:\n","            label = torch.tensor(self.labels[index])\n","            return sample.long().to(device), label.long().to(device)\n","        else:\n","            return sample.long().to(device)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","train_dataset = ClsSamplerDataset(data_train, SEQ_LEN)\n","val_dataset   = ClsSamplerDataset(data_val, SEQ_LEN)\n","\n","train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","val_loader    = DataLoader(val_dataset,   batch_size=BATCH_SIZE)\n","\n","train_cycler  = cycle(train_loader)\n","val_cycler    = cycle(val_loader)\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qoyiGyrsfZ29"},"source":["### TRAINING LOOP"]},{"cell_type":"code","metadata":{"id":"_4s0dfbsfW3f"},"source":["optim = torch.optim.Adam(pre_model.parameters(), lr=LEARNING_RATE)\n","ckpt_path = os.path.join(save_root, \"pre_model_exp1.pt\")\n","\n","writer = SummaryWriter(\n","    log_dir=\"runs/pre_model\",\n","    filename_suffix='_' + '_'.join(map(str, LAYER_SPEC.values()))\n","    )\n","\n","# training loop\n","\n","best_val_loss = np.inf\n","\n","for epoch in range(NUM_EPOCHS):\n","  for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10.,\n","                     desc=f'epoch {epoch}:', colour='green'):\n","      pre_model.train()\n","\n","      for __ in range(GRADIENT_ACCUMULATE_EVERY):\n","          loss = pre_model(next(train_loader))\n","          loss.backward()\n","\n","      torch.nn.utils.clip_grad_norm_(pre_model.parameters(), 0.5)\n","      optim.step()\n","      optim.zero_grad()\n","\n","      # parameter tracking\n","\n","      writer.add_scalar('train_loss', loss.item(),\n","                        epoch * NUM_BATCHES + i\n","                        )\n","\n","      # validate model\n","\n","      if i % VALIDATE_EVERY == 0:\n","          pre_model.eval()\n","          with torch.no_grad():\n","              val_loss = pre_model(next(val_loader)).item()\n","              \n","              writer.add_scalar('val_loss', val_loss,\n","                        epoch * NUM_BATCHES + i\n","                        )\n","\n","              if val_loss < best_val_loss:\n","                  print(f'VL: {val_loss} < BVL: {best_val_loss}')\n","                  best_val_loss = val_loss\n","\n","                  # checkpoint model\n","\n","                  if i > CHECKPOINT_AFTER:\n","                    print(\"Checkpoint saving...\")\n","                    torch.save({\n","                        'train_step': i,\n","                        'model_state_dict': pre_model.state_dict(),\n","                        'LAYER_SPEC': LAYER_SPEC,\n","                        'SEQ_LEN': SEQ_LEN,\n","                        'optim_state_dict': optim.state_dict(),\n","                        'val_loss': val_loss\n","                    }, ckpt_path)\n","                    print(\"Checkpoint saved!\\n\")\n","      \n","      # generate sequence\n","\n","      if i % GENERATE_EVERY == 0:\n","          pre_model.eval()\n","          inp = random.choice(val_dataset)[:-1]\n","          primer_str = decode_tokens(inp.cpu().numpy())\n","          print('\\nprimer:', primer_str, '*' * 100, sep='\\n')\n","\n","          sample = pre_model.generate(inp, GENERATE_LENGTH)\n","          sample_str = decode_tokens(sample.cpu().numpy())\n","          print('output:', sample_str, '\\n', sep='\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MVUY6qYzkdOu"},"source":["### EVALUATE"]},{"cell_type":"code","metadata":{"id":"Tm9Q6o0zkcfp"},"source":["@torch.no_grad()\n","def evaluate(model, dataloader):\n","    model.eval()\n","    cum_loss = 0\n","    counter = 0\n","    for batch in dataloader:\n","        counter += 1\n","        batch_size = batch.shape[0]\n","        val_loss = model(batch).item()\n","        cum_loss += val_loss\n","    avg_loss = cum_loss/(batch_size*counter)\n","    return cum_loss, avg_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNTfwTDxlNgA","executionInfo":{"status":"ok","timestamp":1625506895767,"user_tz":-60,"elapsed":93489,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}},"outputId":"9233365e-9b4b-4492-ebfa-b1aa88e181be"},"source":["evaluate(pre_model, val_loader)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2384.7820653915405, 2.3943595034051612)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"L9kSueJZWbW9"},"source":["Will this code work for finetuning too?"]},{"cell_type":"markdown","metadata":{"id":"bllR8BhQdfpH"},"source":["### GENERATING SEQUENCES"]},{"cell_type":"code","metadata":{"id":"pqGhUlnRGWcM"},"source":["# reading d_items for interpretability \n","d_items_path = os.path.join(data_root, \"d_items.csv\")\n","d_items = pd.read_csv(d_items_path, index_col='ITEMID', dtype={'ITEMID': str})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3gZplilK-EL"},"source":["def decode_token(token):\n","    return str(token2itemid[token])\n","\n","def decode_tokens(tokens):\n","    return ' '.join(list(map(decode_token, tokens)))\n","\n","def token2label(token):\n","    if token == 0:\n","        return '[PAD]'\n","    else:\n","        itemid = token2itemid[token]\n","        x = d_items.loc[itemid, 'LABEL']\n","    return x\n","\n","def tokens2labels(tokens):\n","    return '\\n\\t -> '.join(list(map(token2label, tokens)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cizrIjWVdwIX"},"source":["# fetch and load model state_dict\n","\n","weights_path = os.path.join(data_root, 'models', 'pre_model_exp1.pt')\n","X = torch.load(weights_path, map_location=device)\n","states = X['model_state_dict']\n","base_states = { k[len('net.'):] if k[:len('net.')] == 'net.' else k : v for k, v in states.items()}\n","\n","pre_model.load_state_dict(states)\n","pre_model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjk16p9KeyUv"},"source":["pre_model.eval()\n","with torch.no_grad():\n","    prompt = random.choice(val_dataset)[0:18]\n","    #prompt = torch.cat((prompt, torch.tensor([0]).to(device)))\n","\n","    sample = pre_model.generate(start_tokens=prompt, seq_len = 50, eos_token=0)\n","    print(\"prompt:\\t\", tokens2labels(prompt.cpu().numpy()))\n","    print(\"model:\\t\", tokens2labels(sample.cpu().numpy()), '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Da2PT5WVaEBf","executionInfo":{"status":"ok","timestamp":1625568213097,"user_tz":-60,"elapsed":35242,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}},"outputId":"e7b4b0a2-582e-42ad-bc43-2931dea599ff"},"source":["evaluate(pre_model, train_loader)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3122.3268125355244, 1.5635086692716698)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"YYCK4nwgWlSu"},"source":["### TESTING - DO NOT USE"]},{"cell_type":"code","metadata":{"id":"w47h1Q6_Wnz_"},"source":["test_path    = os.path.join(data_root, 'test_charts.pkl')\n","tsX          = fetch_data(test_path, 'test_tokens')\n","data_test    = {k: torch.from_numpy(v) for k, v in tsX.items()}\n","test_dataset = ClsSamplerDataset(data_test, SEQ_LEN)\n","test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n","test_cycler  = cycle(test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wVDVCWE8vnWZ"},"source":["## FINE-TUNING MODE"]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"M4oE0duaUQIJ","executionInfo":{"status":"ok","timestamp":1625680555541,"user_tz":-60,"elapsed":261,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["class FinetuningWrapper(nn.Module):\n","    def __init__(self, net, num_classes, state_dict = None,\n","                 ignore_index = -100, pad_value = 0, weight = None):\n","        super().__init__()\n","        self.pad_value = pad_value\n","        self.ignore_index = ignore_index\n","        self.num_classes = num_classes\n","        self.weight = weight  # expected to be a tensor of size = num_classes\n","\n","        self.net = copy.deepcopy(net)  # deepcopy is necessary here.\n","        self.max_seq_len = self.net.max_seq_len\n","\n","        # initialise net from pretrained\n","        if state_dict is not None:\n","            self.net.load_state_dict(state_dict)\n","\n","        # define classifier head layers\n","        self.num_features = net.to_logits.in_features * 200\n","        self.net.clf1 = nn.Linear(self.num_features, num_classes, bias=True)\n","\n","    def forward(self, X, Y, predict=False, **kwargs):\n","        Z = self.net(X, return_embeddings=True, **kwargs)\n","        Z = torch.flatten(Z, start_dim=1)\n","        logits = self.net.clf1(Z)\n","        print('net outputted')\n","        loss = F.cross_entropy(logits, Y, weight = self.weight)\n","        print('loss computed')\n","        return logits if predict else loss"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"5a_vWVFHUQIM","executionInfo":{"status":"ok","timestamp":1625679759395,"user_tz":-60,"elapsed":195,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["train_lbl_path = os.path.join(data_root, \"train_labels.pkl\")\n","val_lbl_path = os.path.join(data_root, \"val_labels.pkl\")\n","FT_BATCH_SIZE = 100\n","\n","# fetch labels\n","\n","with open(train_lbl_path, 'rb') as f:\n","    X = pickle.load(f)\n","    train_labels_30 = {k: v['readm_30'] for k, v in  X['train_labels'].items()}\n","    train_labels_7 = {k: v['readm_7'] for k, v in  X['train_labels'].items()}\n","    del X\n","\n","with open(val_lbl_path, 'rb') as f:\n","    X = pickle.load(f)\n","    val_labels_30 = {k: v['readm_30'] for k, v in  X['val_labels'].items()}\n","    val_labels_7 = {k: v['readm_7'] for k, v in  X['val_labels'].items()}\n","    del X\n","\n","# helper for propensities\n","\n","def propensity(di):\n","    x = sum(di.values()) / len(di)\n","    return x\n","\n","# generate datasets and loaders\n","\n","ft_train_dataset = ClsSamplerDataset(data_train, SEQ_LEN, labels=train_labels)\n","ft_val_dataset = ClsSamplerDataset(data_val, SEQ_LEN, labels=val_labels)\n","\n","ft_train_loader = cycle(DataLoader(ft_train_dataset, batch_size=FT_BATCH_SIZE))\n","ft_val_loader = cycle(DataLoader(ft_val_dataset, batch_size=FT_BATCH_SIZE))"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"ggZs5eGAUQIN","executionInfo":{"status":"ok","timestamp":1625679946354,"user_tz":-60,"elapsed":1881,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["# fetch model weights\n","\n","params_path = os.path.join(data_root, 'models', 'pre_model_exp1.pt')\n","X = torch.load(params_path, map_location=device)\n","states = X['model_state_dict']\n","base_states = { k[len('net.'):] if k[:len('net.')] == 'net.' else k : v for k, v in states.items()}"],"execution_count":66,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"zc4WuVlZUQIN"},"source":["### FINETUNING LOOP"]},{"cell_type":"markdown","metadata":{"id":"h_ey6WEKcmEO"},"source":["#### TRAINING"]},{"cell_type":"code","metadata":{"id":"TnFlV5e-l6DS"},"source":["# propensities\n","\n","p = propensity(train_labels_30)\n","weights = torch.tensor([p, 1-p])\n","\n","# initialisation\n","\n","fit_model = FinetuningWrapper(model, num_classes=2,\n","                              state_dict=base_states,\n","                              weight=weights)\n","fit_model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2uJ3x7rmMjQu"},"source":["TODO: bug in F.cross_entropy loss with weights. Got Double not Float error."]},{"cell_type":"code","metadata":{"id":"uuCz-e_aGsEj","executionInfo":{"status":"ok","timestamp":1625680565336,"user_tz":-60,"elapsed":248,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["# set optimiser and paths\n","\n","optim_ft = torch.optim.Adam(fit_model.parameters(), lr=0.001)\n","ckpt_ft_path = os.path.join(save_root, \"fit_model_exp0.pt\")\n","logs_path = os.path.join(save_root, \"logs\", \"fit_model_bal0\")\n","\n","# training loop constants\n","\n","NUM_FT_BATCHES = 100\n","CHECKPOINT_AFTER = 10\n","VALIDATE_EVERY = 2"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"1uqkNxB7UQIN","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"error","timestamp":1625680569379,"user_tz":-60,"elapsed":1672,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}},"outputId":"06d54f56-ea63-45df-fd35-ad2e686e8fec"},"source":["writer = SummaryWriter(logs_path)\n","\n","# training loop\n","\n","best_val_loss = np.inf\n","for i in tqdm.tqdm(range(NUM_FT_BATCHES), mininterval=10., desc='fine-tuning'):\n","    fit_model.train()\n","\n","    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n","        X, Y = next(ft_train_loader)\n","        loss = fit_model(X, Y)\n","        loss.backward()\n","      \n","    writer.add_scalar('loss', loss.item(), i)\n","\n","    print(f'tuning loss: {loss.item()}')\n","    torch.nn.utils.clip_grad_norm_(fit_model.parameters(), 0.5)\n","    optim_ft.step()\n","    optim_ft.zero_grad()\n","\n","    # validate fit_model\n","\n","    if i % VALIDATE_EVERY == 0:\n","        fit_model.eval()\n","        with torch.no_grad():\n","            X, Y = next(ft_val_loader)\n","            val_loss = fit_model(X, Y).item()\n","            writer.add_scalar('val_loss', val_loss, i)\n","            print(f'validation loss: {val_loss}')\n","            \n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                \n","                if i > CHECKPOINT_AFTER:\n","                    print(\"Saving checkpoint...\\n\")\n","                    torch.save({\n","                        'train_step': i,\n","                        'model_state_dict': fit_model.state_dict(),\n","                        'SEQ_LEN': SEQ_LEN,\n","                        'optim_state_dict': optim_ft.state_dict(),\n","                        'val_loss': val_loss\n","                    }, ckpt_ft_path)\n","                    print(\"Checkpoint saved!\\n\")\n","    #else:\n","    #    val_loss = np.nan\n","    #writer.add_scalars('loss', {'tuning_loss': loss.item(), 'val_loss': val_loss}, i)\n","\n","writer.close()"],"execution_count":88,"outputs":[{"output_type":"stream","text":["fine-tuning:   0%|          | 0/100 [00:01<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["net outputted\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-88-853ceae83630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRADIENT_ACCUMULATE_EVERY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-85-776510e18337>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, Y, predict, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'net outputted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss computed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"]}]},{"cell_type":"markdown","metadata":{"id":"-qev_muUEQYJ"},"source":["#### PREDICTION"]},{"cell_type":"markdown","metadata":{"id":"UTNiHurMGwms"},"source":["Weight loading regimes:\n","\n","1. Initialise with random\n","2. Unsupervised pretrain\n","3. Load from `pretrain`\n","4. Finetune for `task`\n","5. Load from `finetune`\n","\n","Here, we are in 5.\n"]},{"cell_type":"code","metadata":{"id":"EsvMPvVdg_fb","executionInfo":{"status":"ok","timestamp":1625677499803,"user_tz":-60,"elapsed":199,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["from sklearn.metrics import accuracy_score, balanced_accuracy_score"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbQEtxYLE8w1","executionInfo":{"status":"ok","timestamp":1625676152598,"user_tz":-60,"elapsed":199,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["# fetch model weights\n","\n","ft_model_path = os.path.join(data_root, 'models', 'fit_model_exp1.pt')\n","X = torch.load(ft_model_path, map_location=device)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"2vB4rO9bEfKF","executionInfo":{"status":"ok","timestamp":1625676175356,"user_tz":-60,"elapsed":199,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":["ft_states = X['model_state_dict']\n","ft_base_states = { k[len('net.'):] if k[:len('net.')] == 'net.' else k : v for k, v in ft_states.items()}"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZsabWGW7JBtb"},"source":["# initialisation\n","fit_model = FinetuningWrapper(model, num_classes=2)\n","fit_model.load_state_dict(ft_states)\n","fit_model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rykUxodGEPa5"},"source":["fit_model.eval()\n","\n","# nums TP, FP, TN, FN\n","\n","TP_tot = 0\n","FP_tot = 0\n","TN_tot = 0\n","FN_tot = 0\n","\n","with torch.no_grad():\n","    for i in range(10):\n","        X, Y_true = next(ft_val_loader)\n","        logits = fit_model(X, Y_true, predict=True)\n","        Y_pred = torch.argmax(logits, dim=1)\n","        y_true, y_pred = Y_true.cpu(), Y_pred.cpu()\n","        TP = ((y_true == 1) & (y_pred == 1)).sum()\n","        FN = (y_true > y_pred).sum()\n","        FP = (y_true < y_pred).sum()\n","        TN = ((y_true == 0) & (y_pred == 0)).sum()\n","        print(f'TP = {TP}', f'FP = {FP}', f'TN = {TN}', f'FN = {FN}')\n","        #print(f'TP: {Y_true.numpy().sum()}', f'pP: {Y_pred.numpy().sum()}')\n","        print(accuracy_score(y_true, y_pred, normalize=True), '\\n')\n","        print(balanced_accuracy_score(y_true, y_pred), '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-IutJEDdUIh","executionInfo":{"status":"ok","timestamp":1625669710575,"user_tz":-60,"elapsed":227,"user":{"displayName":"James Cann","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj37bBvXyKMzK890sou9cHG0PcfWI1S5-uihybe=s64","userId":"00456860292205766006"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"VcbTyGwCdzDz"},"source":[""],"execution_count":null,"outputs":[]}]}